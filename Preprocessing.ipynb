{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FTGi4s-zS7Ew",
        "juInQLTsTHn6",
        "QfkYGIwLTWXG",
        "UYEOv5bFTZju"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-dhN9kkYuxL"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJa_bm-FDbq"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTGi4s-zS7Ew"
      },
      "source": [
        "# **Data Loading & Formatting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-iT0IONY50O"
      },
      "source": [
        "# Extract the raw data from the txt file.\n",
        "def load_text(filename):\n",
        "    file = open(filename,'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Create a dictionary to pair (imageid,list of captions)\n",
        "def load_description(doc):\n",
        "    mapping = dict()\n",
        "    for line in doc.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        if len(tokens)<2:\n",
        "            continue\n",
        "        image_id,image_desc = tokens[0],tokens[1:]\n",
        "        image_id = image_id.split('.')[0]\n",
        "\n",
        "        image_desc = ' '.join(image_desc)\n",
        "        if image_id not in mapping:\n",
        "            mapping[image_id] = list()\n",
        "        mapping[image_id].append(image_desc)\n",
        "    return mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt10WqyLlcTM",
        "outputId": "eba846a2-3536-4688-ffe7-574517df57d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Define a path to the Flickr8k.token.txt file of the dataset.\n",
        "tokenFile = '/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/Flickr8k.token.txt'\n",
        "doc = load_text(tokenFile)\n",
        "descriptions = load_description(doc)\n",
        "print('Number of samples loaded: %d ' % len(descriptions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juInQLTsTHn6"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBQ7goo8PwU0"
      },
      "source": [
        "# Pre-process the captions as follows.\n",
        "# 1. take a caption and split it into words.\n",
        "# 2. Convert Each word in lowercase.\n",
        "# 3. Remove punctuations, if there is any.\n",
        "# 4. Make sure each word contains only alphabates.\n",
        "def clean_description(description):\n",
        "    print(type(description))\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    for key,desc_list in description.items():\n",
        "        temp_list = list()\n",
        "        for i in range(len(desc_list)):\n",
        "            print(len(desc_list))\n",
        "            desc = desc_list[i]\n",
        "            desc1 = desc.split()\n",
        "            desc2 = [word.lower() for word in desc1]\n",
        "            desc3 = [word.translate(table) for word in desc2]\n",
        "            desc4 = [word for word in desc3 if len(word)>1]\n",
        "            desc5 = [word for word in desc4 if word.isalpha()]\n",
        "            desc6 = ' '.join(desc5)\n",
        "            temp_list.append(desc6)\n",
        "        description[key]=temp_list\n",
        "        \n",
        "    return description\n",
        "descriptions = clean_description(descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfkYGIwLTWXG"
      },
      "source": [
        "# **Data Saving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLSnrBcQOewn"
      },
      "source": [
        "# Make a list of -> imageid+' '+caption\n",
        "# Join all list elements with \\n character.\n",
        "# and Write resultant string in a text file. \n",
        "def save_description(description,filename):\n",
        "    lines = list()\n",
        "    print(type(description))\n",
        "    for key,desc_list in description.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key+' '+desc)\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename,'w')\n",
        "    file.write(data)\n",
        "    file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLj1_VY_7ZVJ"
      },
      "source": [
        "descrOut = '/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/description_new.txt'\n",
        "save_description(descriptions, descrOut)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYEOv5bFTZju"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekk1f5SiOl_k"
      },
      "source": [
        "# It shows that how many distinct words across all captions.\n",
        "def to_vocabulary(description):\n",
        "    all_desc = set()\n",
        "\n",
        "    for key in description.keys():\n",
        "        [all_desc.update(d.split()) for d in description[key]]\n",
        "    return all_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PJCjhHWWUA",
        "outputId": "320acf8a-f911-4d41-e8cc-6788fb3563a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 8763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glSdfbrMNo-2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}