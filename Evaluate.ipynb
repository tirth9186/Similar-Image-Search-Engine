{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo3gyhI7JB53",
        "outputId": "dcbadd06-8b68-432a-871e-aa3922f007a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKVA-DZikoHU",
        "outputId": "b5354d11-bd6b-49ce-f6d9-e8d3a26a757e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eToZldpxUJck",
        "outputId": "3a35e45a-d3e0-45e2-f5c1-8ddfd09eddc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXCBrVk9H2zi"
      },
      "source": [
        "from numpy import argmax,array\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,Dropout\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "import pickle\n",
        "from pickle import load\n",
        "from pickle import dump\n",
        "from PIL import Image\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "from keras.layers.merge import add"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJvSN99eJEot"
      },
      "source": [
        "def load_doc(filename):\n",
        "    file = open(filename,'r')\n",
        "    text = file.read()\n",
        "    file.close()    \n",
        "    return text\n",
        "\n",
        "def load_set(filename):\n",
        "    doc = load_doc(filename)\n",
        "    dataset = list()\n",
        "    \n",
        "    for line in doc.split('\\n'):\n",
        "        if len(line)<1:\n",
        "            continue\n",
        "        identifier = line.split('.')[0]\n",
        "        dataset.append(identifier)\n",
        "    return set(dataset)\n",
        "\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "    doc = load_doc(filename)\n",
        "    descriptions = dict()\n",
        "    \n",
        "    for line in doc.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        image_id, image_desc = tokens[0],tokens[1:]\n",
        "        #if image_id not in dataset ignore\n",
        "        if image_id in dataset:\n",
        "            if image_id not in descriptions:\n",
        "                descriptions[image_id] = list()\n",
        "            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "            descriptions[image_id].append(desc)\n",
        "    return descriptions\n",
        "\n",
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = pickle.load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plPdEIKbJNUA"
      },
      "source": [
        "def word_for_id(integer,tokenizer):\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==integer:\n",
        "      return word\n",
        "  return None\n",
        "\n",
        "def data_generator(descriptions, photos, tokenizer, max_length, vocab_size):\n",
        "\twhile 1:\n",
        "\t\tfor key, desc_list in descriptions.items():\n",
        "\t\t\tphoto = photos[key][0]\n",
        "\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo, vocab_size)\n",
        "\t\t\tyield [in_img, in_seq], out_word\n",
        "\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence],maxlen = max_length)\n",
        "        yhat = model.predict([photo,sequence],verbose=0)\n",
        "        yhat = argmax(yhat)\n",
        "        word = word_for_id(yhat,tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "\n",
        "        in_text += ' '+word\n",
        "        if word == 'endseq':\n",
        "            break\t\n",
        "    return in_text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOP_BaxnrWTZ"
      },
      "source": [
        "def create_sequences(tokenizer, max_length, desc_list, photo, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tfor desc in desc_list:\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])\n",
        "\t\tfor i in range(1, len(seq[0])):\n",
        "\t\t\tin_seq, out_seq = seq[0][:i], seq[0][i]\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)\n",
        "\t\t\tX1.append(photo)\n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq.flatten())\n",
        "\treturn array(X1), array(X2), array(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eDdDd0ya6cj"
      },
      "source": [
        "def to_lines(descriptions):\n",
        "    all_desc = list()\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.append(des) for des in descriptions[key]]\n",
        "    return all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer    \n",
        "\n",
        "def find_max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vL48w_Ebc7F"
      },
      "source": [
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "    actual, predicted = list(), list()\n",
        "    \n",
        "    for key, desc_list in descriptions.items():\n",
        "            yhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "            references = [d.split() for d in desc_list]\n",
        "            actual.append(references)\n",
        "            predicted.append(yhat.split())\n",
        "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsaaSugiZ77y"
      },
      "source": [
        "filename = '/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "filename = '/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "test = load_set(filename)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoWD125mUK_T",
        "outputId": "9dc67e18-7448-4c07-a1fe-006bf1a99094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "all = train.union(test)\n",
        "descriptions = load_clean_descriptions('/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/descriptions.txt', all)\n",
        "tokenizer = create_tokenizer(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "\n",
        "# determine the maximum sequence length\n",
        "max_length = find_max_length(descriptions)\n",
        "print('Description Length: %d' % max_length)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 8170\n",
            "Description Length: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZB9Rb5xjWVS",
        "outputId": "43f79e38-24f2-421c-e36d-4f115e510518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "testImgList ='/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "testImg = load_set(testImgList)\n",
        "print('Dataset: %d' % len(testImg))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_text/descriptions.txt', testImg)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('/content/drive/My Drive/College/IRS Innovative/flicker8k-dataset/Flickr8k_Dataset/features_resnet.pkl', testImg)\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "\n",
        "weights = '/content/drive/My Drive/College/IRS Innovative/ResNet50/model_19.h5'\n",
        "model = load_model(weights)\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\n",
        "# prepare tokenizer\n",
        "# tokenizer = create_tokenizer(train_descriptions)\n",
        "# save the tokenizer\n",
        "# dump(tokenizer, open(code_root_dir + 'tokenizer_resnet50.pkl', 'wb'))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Descriptions: test=1000\n",
            "Photos: test=1000\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "BLEU-1: 0.502172\n",
            "BLEU-2: 0.256557\n",
            "BLEU-3: 0.175373\n",
            "BLEU-4: 0.081145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4q9wjCS89CQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}